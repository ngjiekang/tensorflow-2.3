from flask import Flask, request
import tensorflow as tf
import os
from tensorflow.python.tools import saved_model_cli

app = Flask(__name__)

@app.route('/load_model', methods=['POST'])
def load_model():
    # Simulating receiving a model directory path from an untrusted source
    model_dir = request.form['model_dir']

    # Potential taint vulnerability if model_dir is not validated
    # and directly used to load a TensorFlow SavedModel
    model = tf.saved_model.load(model_dir)  # Hypothetical risky operation

    return "Model loaded successfully!"

@app.route('/inspect_model', methods=['GET'])
def inspect_model():
    # Simulating receiving a model directory path as a query parameter from an untrusted source
    model_dir = request.args.get('model_dir')

    # Directly passing untrusted input to saved_model_cli.inspect to inspect the model
    # This could lead to information disclosure if model_dir is manipulated
    info = saved_model_cli.show_all(model_dir)  # Hypothetical risky operation

    return info

@app.route('/execute_model_function', methods=['POST'])
def execute_model_function():
    # Simulating receiving model execution parameters from untrusted sources
    model_dir = request.form['model_dir']
    tag_set = request.form['tag_set']
    signature_def_key = request.form['signature_def_key']
    inputs = request.form['inputs']  # Assume this is a simplified representation

    # This operation could be vulnerable if inputs are crafted to exploit the model execution
    output = saved_model_cli.run_saved_model_with_feed_dict(
        model_dir,
        tag_set,
        signature_def_key,
        inputs  # Hypothetical risky operation
    )

    return f"Model executed, output: {output}"

if __name__ == "__main__":
    app.run(debug=True)
